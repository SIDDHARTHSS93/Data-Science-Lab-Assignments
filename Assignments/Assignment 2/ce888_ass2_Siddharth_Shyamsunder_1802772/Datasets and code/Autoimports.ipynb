{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report \n",
    "from sklearn import svm,preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the training dataset: 5200\n"
     ]
    }
   ],
   "source": [
    "data3=open('imports-85.data','r',encoding='utf-8')\n",
    "data3=data3.read()\n",
    "#Reading data from the dataset\n",
    "data3=\",\".join(data3.splitlines())\n",
    "\n",
    "data3=data3.split(',')\n",
    "\n",
    "data4=[]\n",
    "\n",
    "count=5200\n",
    "print('Length of the training dataset:',count)\n",
    "for i in range(count//26):\n",
    "    data4.append([])\n",
    "i=0\n",
    "\n",
    "for j in range(0,(count)):\n",
    "    if(j%26==0 and j!=0):\n",
    "        i+=1\n",
    "\n",
    "        \n",
    "    data4[i].append(data3[j])\n",
    "\n",
    "#Copying Dataframe into csv \n",
    "data=\"symboling,normalized-losses,make,fuel-type,aspiration,num-of-doors,body-style,drive-wheels,engine-location,wheel-base,length,width,height,curb-weight,engine-type,num-of-cylinders,engine-size,fuel-system,bore,stroke,compression-ratio,horsepower,peak-rpm,city-mpg,highway-mpg,price\".split(',')\n",
    "csvdata=data\n",
    "with open(\"Autoimport.csv\",'w',encoding='utf-8') as csvFile:\n",
    "    writer=csv.writer(csvFile)\n",
    "    writer.writerow(csvdata)\n",
    "csvFile.close()\n",
    "\n",
    "data=data4\n",
    "csvdata=data\n",
    "with open(\"Autoimport.csv\",'a',encoding='utf-8') as csvFile:\n",
    "    writer=csv.writer(csvFile)\n",
    "    writer.writerows(csvdata)\n",
    "csvFile.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    symboling  normalized-losses  fuel-type  aspiration  num-of-doors  \\\n",
      "3           2              164.0          1           0             0   \n",
      "4           2              164.0          1           0             0   \n",
      "6           1              158.0          1           0             0   \n",
      "8           1              158.0          1           1             0   \n",
      "10          2              192.0          1           0             1   \n",
      "\n",
      "    body-style  drive-wheels  engine-location  wheel-base  length  ...  \\\n",
      "3            3             1                0        99.8   176.6  ...   \n",
      "4            3             0                0        99.4   176.6  ...   \n",
      "6            3             1                0       105.8   192.7  ...   \n",
      "8            3             1                0       105.8   192.7  ...   \n",
      "10           3             2                0       101.2   176.8  ...   \n",
      "\n",
      "    engine-size  fuel-system  bore  stroke  compression-ratio  horsepower  \\\n",
      "3           109            4  3.19     3.4               10.0       102.0   \n",
      "4           136            4  3.19     3.4                8.0       115.0   \n",
      "6           136            4  3.19     3.4                8.5       110.0   \n",
      "8           131            4  3.13     3.4                8.3       140.0   \n",
      "10          108            4  3.50     2.8                8.8       101.0   \n",
      "\n",
      "    peak-rpm  city-mpg  highway-mpg    price  \n",
      "3     5500.0        24           30  13950.0  \n",
      "4     5500.0        18           22  17450.0  \n",
      "6     5500.0        19           25  17710.0  \n",
      "8     5500.0        17           20  23875.0  \n",
      "10    5800.0        23           29  16430.0  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "#Reading Data Frame\n",
    "data3=pd.read_csv('Autoimport.csv')\n",
    "data3=data3.dropna()\n",
    "Y=data3['make']\n",
    "encoder=LabelEncoder()\n",
    "encoder1=LabelEncoder()\n",
    "encoder2=LabelEncoder()\n",
    "encoder3=LabelEncoder()\n",
    "encoder4=LabelEncoder()\n",
    "encoder5=LabelEncoder()\n",
    "encoder6=LabelEncoder()\n",
    "encoder7=LabelEncoder()\n",
    "encoder8=LabelEncoder()\n",
    "encoder9=LabelEncoder()\n",
    "\n",
    "Y=encoder.fit_transform(data3.iloc[:,2].astype(str))\n",
    "X=data3.drop('make',axis=1)\n",
    "X['fuel-type']=encoder1.fit_transform(data3.iloc[:,3].astype(str))          \n",
    "X['aspiration']=encoder2.fit_transform(data3.iloc[:,4].astype(str)) \n",
    "X['num-of-doors']=encoder3.fit_transform(data3.iloc[:,5].astype(str))\n",
    "X['body-style']=encoder4.fit_transform(data3.iloc[:,6].astype(str))\n",
    "X['drive-wheels']=encoder5.fit_transform(data3.iloc[:,7].astype(str))\n",
    "X['engine-location']=encoder6.fit_transform(data3.iloc[:,8].astype(str))\n",
    "X['engine-type']=encoder7.fit_transform(data3.iloc[:,14].astype(str))\n",
    "X['num-of-cylinders']=encoder8.fit_transform(data3.iloc[:,15].astype(str))\n",
    "X['fuel-system']=encoder9.fit_transform(data3.iloc[:,17].astype(str))\n",
    "print(X.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Learning data with 80% Training and 20% Testing data using Random Forest Method\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,train_size = 0.8,test_size=0.2,random_state=0)\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random forest prediction vs actual tested reading: 0.8709677419354839\n",
      "The confusion Matrix is as Below:\n",
      "\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 6 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         audi       0.00      0.00      0.00         0\n",
      "          bmw       1.00      1.00      1.00         1\n",
      "    chevrolet       0.00      0.00      0.00         1\n",
      "        dodge       0.50      1.00      0.67         1\n",
      "        honda       0.67      1.00      0.80         2\n",
      "       jaguar       0.00      0.00      0.00         0\n",
      "        mazda       1.00      1.00      1.00         3\n",
      "mercedes-benz       1.00      1.00      1.00         1\n",
      "   mitsubishi       0.67      1.00      0.80         2\n",
      "       nissan       1.00      1.00      1.00         2\n",
      "       peugot       1.00      1.00      1.00         2\n",
      "     plymouth       0.00      0.00      0.00         2\n",
      "      porsche       0.00      0.00      0.00         0\n",
      "         saab       1.00      1.00      1.00         1\n",
      "       subaru       1.00      1.00      1.00         4\n",
      "       toyota       1.00      0.86      0.92         7\n",
      "   volkswagen       1.00      1.00      1.00         1\n",
      "        volvo       0.50      1.00      0.67         1\n",
      "\n",
      "    micro avg       0.87      0.87      0.87        31\n",
      "    macro avg       0.63      0.71      0.66        31\n",
      " weighted avg       0.83      0.87      0.84        31\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Evaluating Confusion Matrix and Classification Evaluation Report after Random Forest Learning\n",
    "ypred = clf.predict(x_test)\n",
    "Y1=list(encoder.inverse_transform(y_test))\n",
    "Y2=list(encoder.inverse_transform(ypred))\n",
    "print(\"Accuracy of Random forest prediction vs actual tested reading:\",accuracy_score(y_test, ypred))\n",
    "print('The confusion Matrix is as Below:\\n')\n",
    "\n",
    "print(confusion_matrix(Y1,Y2,labels=list(encoder.classes_)))\n",
    "print(classification_report(Y1,Y2,labels=list(encoder.classes_)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Probability Fields using Binning Techniques\n",
    "yproba=clf.predict_proba(X)\n",
    "\n",
    "binlab=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "\n",
    "bins=[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    symboling  normalized-losses  fuel-type  aspiration  num-of-doors  \\\n",
      "3           2              164.0          1           0             0   \n",
      "4           2              164.0          1           0             0   \n",
      "6           1              158.0          1           0             0   \n",
      "8           1              158.0          1           1             0   \n",
      "10          2              192.0          1           0             1   \n",
      "\n",
      "    body-style  drive-wheels  engine-location  wheel-base  length  ...   p1  \\\n",
      "3            3             1                0        99.8   176.6  ...  0.8   \n",
      "4            3             0                0        99.4   176.6  ...  0.8   \n",
      "6            3             1                0       105.8   192.7  ...  0.8   \n",
      "8            3             1                0       105.8   192.7  ...  0.9   \n",
      "10           3             2                0       101.2   176.8  ...  0.1   \n",
      "\n",
      "     p2   p3   p4   p5   p6   p7   p8   p9  p10  \n",
      "3   0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  \n",
      "4   0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  \n",
      "6   0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  \n",
      "8   0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  \n",
      "10  0.9  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "# Adding Probability fields to the entire feature dataset. \n",
    "X['p1']=pd.cut(yproba[:,0],bins,labels=binlab, include_lowest=True)\n",
    "X['p2']=pd.cut(yproba[:,1],bins,labels=binlab, include_lowest=True)\n",
    "X['p3']=pd.cut(yproba[:,2],bins,labels=binlab, include_lowest=True)\n",
    "X['p4']=pd.cut(yproba[:,3],bins,labels=binlab, include_lowest=True)\n",
    "X['p5']=pd.cut(yproba[:,4],bins,labels=binlab, include_lowest=True)\n",
    "X['p6']=pd.cut(yproba[:,5],bins,labels=binlab, include_lowest=True)\n",
    "X['p7']=pd.cut(yproba[:,6],bins,labels=binlab, include_lowest=True)\n",
    "X['p8']=pd.cut(yproba[:,7],bins,labels=binlab, include_lowest=True)\n",
    "X['p9']=pd.cut(yproba[:,8],bins,labels=binlab, include_lowest=True)\n",
    "X['p10']=pd.cut(yproba[:,9],bins,labels=binlab, include_lowest=True)\n",
    "\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=100,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dividing the entire dataset into training and test data and performing Decision Tree classification.\n",
    "xtr1, xte1, ytr1, yte1 = train_test_split(X,Y,train_size = 0.8,test_size=0.2,random_state=0)\n",
    "dt = DecisionTreeClassifier(min_samples_split=100)\n",
    "dt.fit(xtr1,ytr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred1 = dt.predict(xte1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of using decision tree after random forest: 0.3548387096774194\n",
      "The confusion Matrix is as Below:\n",
      "\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]]\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         audi       0.00      0.00      0.00         0\n",
      "          bmw       0.00      0.00      0.00         1\n",
      "    chevrolet       0.00      0.00      0.00         1\n",
      "        dodge       0.00      0.00      0.00         1\n",
      "        honda       1.00      1.00      1.00         2\n",
      "       jaguar       0.00      0.00      0.00         0\n",
      "        mazda       0.00      0.00      0.00         3\n",
      "mercedes-benz       0.00      0.00      0.00         1\n",
      "   mitsubishi       0.00      0.00      0.00         2\n",
      "       nissan       1.00      1.00      1.00         2\n",
      "       peugot       0.00      0.00      0.00         2\n",
      "     plymouth       0.00      0.00      0.00         2\n",
      "      porsche       0.00      0.00      0.00         0\n",
      "         saab       0.00      0.00      0.00         1\n",
      "       subaru       0.00      0.00      0.00         4\n",
      "       toyota       0.26      1.00      0.41         7\n",
      "   volkswagen       0.00      0.00      0.00         1\n",
      "        volvo       0.00      0.00      0.00         1\n",
      "\n",
      "    micro avg       0.35      0.35      0.35        31\n",
      "    macro avg       0.13      0.17      0.13        31\n",
      " weighted avg       0.19      0.35      0.22        31\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Evaluating Accuracy, Confusion Matrix and Classification Report on Decision Tree After distillation of Random Forest \n",
    "print(\"Accuracy of using decision tree after random forest:\",accuracy_score(yte1, ypred1))\n",
    "Y3=list(encoder.inverse_transform(yte1))\n",
    "Y4=list(encoder.inverse_transform(ypred1))\n",
    "print('The confusion Matrix is as Below:\\n')\n",
    "print(confusion_matrix(Y3,Y4,labels=list(encoder.classes_)))\n",
    "print(classification_report(Y3,Y4,labels=list(encoder.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trying other Techniques after distillation namely Support Vector Machine\n",
    "xtr1, xte1, ytr1, yte1 = train_test_split(X,Y,train_size = 0.8,test_size=0.2,random_state=0)\n",
    "support = svm.SVC(gamma=0.01, C=100.)\n",
    "support.fit(xtr1,ytr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred1 = support.predict(xte1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of using Support Vector Machine after random forest: 0.22580645161290322\n",
      "The confusion Matrix is as Below:\n",
      "\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]]\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         audi       0.00      0.00      0.00         0\n",
      "          bmw       0.00      0.00      0.00         1\n",
      "    chevrolet       0.00      0.00      0.00         1\n",
      "        dodge       0.00      0.00      0.00         1\n",
      "        honda       0.00      0.00      0.00         2\n",
      "       jaguar       0.00      0.00      0.00         0\n",
      "        mazda       0.00      0.00      0.00         3\n",
      "mercedes-benz       0.00      0.00      0.00         1\n",
      "   mitsubishi       0.00      0.00      0.00         2\n",
      "       nissan       0.00      0.00      0.00         2\n",
      "       peugot       0.00      0.00      0.00         2\n",
      "     plymouth       0.00      0.00      0.00         2\n",
      "      porsche       0.00      0.00      0.00         0\n",
      "         saab       0.00      0.00      0.00         1\n",
      "       subaru       0.00      0.00      0.00         4\n",
      "       toyota       0.23      1.00      0.38         7\n",
      "   volkswagen       0.00      0.00      0.00         1\n",
      "        volvo       0.00      0.00      0.00         1\n",
      "\n",
      "    micro avg       0.23      0.23      0.23        31\n",
      "    macro avg       0.01      0.06      0.02        31\n",
      " weighted avg       0.05      0.23      0.09        31\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of using Support Vector Machine after random forest:\",accuracy_score(yte1, ypred1))\n",
    "Y5=list(encoder.inverse_transform(yte1))\n",
    "Y6=list(encoder.inverse_transform(ypred1))\n",
    "print('The confusion Matrix is as Below:\\n')\n",
    "print(confusion_matrix(Y5,Y6,labels=list(encoder.classes_)))\n",
    "print(classification_report(Y5,Y6,labels=list(encoder.classes_)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=100,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making use of training data without distillation using single not ensemble method like Decision Tree.\n",
    "dt1=DecisionTreeClassifier(min_samples_split=100)\n",
    "dt1.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = dt1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree prediction without distillation: 0.1935483870967742\n",
      "The confusion Matrix is as Below:\n",
      "\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 4 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]]\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         audi       0.00      0.00      0.00         0\n",
      "          bmw       0.00      0.00      0.00         1\n",
      "    chevrolet       0.00      0.00      0.00         1\n",
      "        dodge       0.00      0.00      0.00         1\n",
      "        honda       0.00      0.00      0.00         2\n",
      "       jaguar       0.00      0.00      0.00         0\n",
      "        mazda       0.00      0.00      0.00         3\n",
      "mercedes-benz       0.00      0.00      0.00         1\n",
      "   mitsubishi       0.00      0.00      0.00         2\n",
      "       nissan       0.11      1.00      0.20         2\n",
      "       peugot       0.00      0.00      0.00         2\n",
      "     plymouth       0.00      0.00      0.00         2\n",
      "      porsche       0.00      0.00      0.00         0\n",
      "         saab       0.00      0.00      0.00         1\n",
      "       subaru       0.00      0.00      0.00         4\n",
      "       toyota       0.31      0.57      0.40         7\n",
      "   volkswagen       0.00      0.00      0.00         1\n",
      "        volvo       0.00      0.00      0.00         1\n",
      "\n",
      "    micro avg       0.19      0.19      0.19        31\n",
      "    macro avg       0.02      0.09      0.03        31\n",
      " weighted avg       0.08      0.19      0.10        31\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "Y7=list(encoder.inverse_transform(y_test))\n",
    "Y8=list(encoder.inverse_transform(ypred))\n",
    "print(\"Accuracy of Decision Tree prediction without distillation:\",accuracy_score(y_test, ypred))\n",
    "print('The confusion Matrix is as Below:\\n')\n",
    "print(confusion_matrix(Y7,Y8,labels=list(encoder.classes_)))\n",
    "print(classification_report(Y7,Y8,labels=list(encoder.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    symboling  normalized-losses  fuel-type  aspiration  num-of-doors  \\\n",
      "3           2              164.0          1           0             0   \n",
      "4           2              164.0          1           0             0   \n",
      "6           1              158.0          1           0             0   \n",
      "8           1              158.0          1           1             0   \n",
      "10          2              192.0          1           0             1   \n",
      "\n",
      "    body-style  drive-wheels  engine-location  wheel-base  length  ...  \\\n",
      "3            3             1                0        99.8   176.6  ...   \n",
      "4            3             0                0        99.4   176.6  ...   \n",
      "6            3             1                0       105.8   192.7  ...   \n",
      "8            3             1                0       105.8   192.7  ...   \n",
      "10           3             2                0       101.2   176.8  ...   \n",
      "\n",
      "    engine-size  fuel-system  bore  stroke  compression-ratio  horsepower  \\\n",
      "3           109            4  3.19     3.4               10.0       102.0   \n",
      "4           136            4  3.19     3.4                8.0       115.0   \n",
      "6           136            4  3.19     3.4                8.5       110.0   \n",
      "8           131            4  3.13     3.4                8.3       140.0   \n",
      "10          108            4  3.50     2.8                8.8       101.0   \n",
      "\n",
      "    peak-rpm  city-mpg  highway-mpg    price  \n",
      "3     5500.0        24           30  13950.0  \n",
      "4     5500.0        18           22  17450.0  \n",
      "6     5500.0        19           25  17710.0  \n",
      "8     5500.0        17           20  23875.0  \n",
      "10    5800.0        23           29  16430.0  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "    symboling  normalized-losses  fuel-type  aspiration  num-of-doors  \\\n",
      "3           2              164.0          1           0             0   \n",
      "4           2              164.0          1           0             0   \n",
      "6           1              158.0          1           0             0   \n",
      "8           1              158.0          1           1             0   \n",
      "10          2              192.0          1           0             1   \n",
      "\n",
      "    body-style  drive-wheels  engine-location  wheel-base  length  ...   p1  \\\n",
      "3            3             1                0        99.8   176.6  ...  0.1   \n",
      "4            3             0                0        99.4   176.6  ...  0.1   \n",
      "6            3             1                0       105.8   192.7  ...  0.1   \n",
      "8            3             1                0       105.8   192.7  ...  0.1   \n",
      "10           3             2                0       101.2   176.8  ...  0.1   \n",
      "\n",
      "     p2   p3   p4   p5   p6   p7   p8   p9  p10  \n",
      "3   0.1  0.1  0.1  0.2  0.1  0.1  0.1  0.2  0.2  \n",
      "4   0.1  0.1  0.1  0.2  0.1  0.1  0.1  0.2  0.2  \n",
      "6   0.1  0.1  0.1  0.2  0.1  0.1  0.1  0.2  0.2  \n",
      "8   0.1  0.1  0.1  0.2  0.1  0.1  0.1  0.2  0.2  \n",
      "10  0.1  0.1  0.1  0.2  0.1  0.1  0.1  0.2  0.2  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "# Adding Probability fields to the entire feature dataset and binning. \n",
    "X1=data3.drop('make',axis=1)\n",
    "X1['fuel-type']=encoder1.fit_transform(data3.iloc[:,3].astype(str))          \n",
    "X1['aspiration']=encoder2.fit_transform(data3.iloc[:,4].astype(str)) \n",
    "X1['num-of-doors']=encoder3.fit_transform(data3.iloc[:,5].astype(str))\n",
    "X1['body-style']=encoder4.fit_transform(data3.iloc[:,6].astype(str))\n",
    "X1['drive-wheels']=encoder5.fit_transform(data3.iloc[:,7].astype(str))\n",
    "X1['engine-location']=encoder6.fit_transform(data3.iloc[:,8].astype(str))\n",
    "X1['engine-type']=encoder7.fit_transform(data3.iloc[:,14].astype(str))\n",
    "X1['num-of-cylinders']=encoder8.fit_transform(data3.iloc[:,15].astype(str))\n",
    "X1['fuel-system']=encoder9.fit_transform(data3.iloc[:,17].astype(str))\n",
    "print(X1.head())\n",
    "yproba1=dt1.predict_proba(X1)\n",
    "\n",
    "binlab=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "\n",
    "bins=[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "\n",
    "X1['p1']=pd.cut(yproba1[:,0],bins,labels=binlab, include_lowest=True)\n",
    "X1['p2']=pd.cut(yproba1[:,1],bins,labels=binlab, include_lowest=True)\n",
    "X1['p3']=pd.cut(yproba1[:,2],bins,labels=binlab, include_lowest=True)\n",
    "X1['p4']=pd.cut(yproba1[:,3],bins,labels=binlab, include_lowest=True)\n",
    "X1['p5']=pd.cut(yproba1[:,4],bins,labels=binlab, include_lowest=True)\n",
    "X1['p6']=pd.cut(yproba1[:,5],bins,labels=binlab, include_lowest=True)\n",
    "X1['p7']=pd.cut(yproba1[:,6],bins,labels=binlab, include_lowest=True)\n",
    "X1['p8']=pd.cut(yproba1[:,7],bins,labels=binlab, include_lowest=True)\n",
    "X1['p9']=pd.cut(yproba1[:,8],bins,labels=binlab, include_lowest=True)\n",
    "X1['p10']=pd.cut(yproba1[:,9],bins,labels=binlab, include_lowest=True)\n",
    "\n",
    "\n",
    "print(X1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=100,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying Decision Tree after Distillation using individual Learning like Decision Tree\n",
    "xtr1, xte1, ytr1, yte1 = train_test_split(X1,Y,train_size = 0.8,test_size=0.2,random_state=0)\n",
    "dt2 = DecisionTreeClassifier(min_samples_split=100)\n",
    "dt2.fit(xtr1,ytr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred2 = dt2.predict(xte1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of using decision tree after distillation using decision tree: 0.1935483870967742\n",
      "The confusion Matrix is as Below:\n",
      "\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 4 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]]\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         audi       0.00      0.00      0.00         0\n",
      "          bmw       0.00      0.00      0.00         1\n",
      "    chevrolet       0.00      0.00      0.00         1\n",
      "        dodge       0.00      0.00      0.00         1\n",
      "        honda       0.00      0.00      0.00         2\n",
      "       jaguar       0.00      0.00      0.00         0\n",
      "        mazda       0.00      0.00      0.00         3\n",
      "mercedes-benz       0.00      0.00      0.00         1\n",
      "   mitsubishi       0.00      0.00      0.00         2\n",
      "       nissan       0.11      1.00      0.20         2\n",
      "       peugot       0.00      0.00      0.00         2\n",
      "     plymouth       0.00      0.00      0.00         2\n",
      "      porsche       0.00      0.00      0.00         0\n",
      "         saab       0.00      0.00      0.00         1\n",
      "       subaru       0.00      0.00      0.00         4\n",
      "       toyota       0.31      0.57      0.40         7\n",
      "   volkswagen       0.00      0.00      0.00         1\n",
      "        volvo       0.00      0.00      0.00         1\n",
      "\n",
      "    micro avg       0.19      0.19      0.19        31\n",
      "    macro avg       0.02      0.09      0.03        31\n",
      " weighted avg       0.08      0.19      0.10        31\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of using decision tree after distillation using decision tree:\",accuracy_score(yte1, ypred2))\n",
    "Y9=list(encoder.inverse_transform(yte1))\n",
    "Y10=list(encoder.inverse_transform(ypred2))\n",
    "print('The confusion Matrix is as Below:\\n')\n",
    "print(confusion_matrix(Y9,Y10,labels=list(encoder.classes_)))\n",
    "print(classification_report(Y9,Y10,labels=list(encoder.classes_)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
