{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report \n",
    "from sklearn import svm,preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data=open('ecoli.data','r',encoding='utf-8')\n",
    "data=data.read()\n",
    "#Reading data from the dataset\n",
    "data=\" \".join(data.splitlines())\n",
    "\n",
    "data=data.split()\n",
    "\n",
    "data2=[]\n",
    "\n",
    "count=len(data)\n",
    "\n",
    "for i in range(count//9):\n",
    "    data2.append([])\n",
    "i=0\n",
    "\n",
    "for j in range(0,(count)):\n",
    "    if(j%9==0 and j!=0):\n",
    "        i+=1\n",
    "\n",
    "        \n",
    "    data2[i].append(data[j])\n",
    "\n",
    "\n",
    "#Copying Dataframe into csv \n",
    "data=\"Sequence Name,mcg,gvh,lip,chg,aac,alm1,alm2,Class\".split(',')\n",
    "csvdata=data\n",
    "with open(\"ecoli.csv\",'w',encoding='utf-8') as csvFile:\n",
    "    writer=csv.writer(csvFile)\n",
    "    writer.writerow(csvdata)\n",
    "csvFile.close()\n",
    "\n",
    "data=data2\n",
    "csvdata=data\n",
    "with open(\"ecoli.csv\",'a',encoding='utf-8') as csvFile:\n",
    "    writer=csv.writer(csvFile)\n",
    "    writer.writerows(csvdata)\n",
    "csvFile.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sequence Name   mcg   gvh   lip  chg   aac  alm1  alm2\n",
      "0              1  0.49  0.29  0.48  0.5  0.56  0.24  0.35\n",
      "1              2  0.07  0.40  0.48  0.5  0.54  0.35  0.44\n",
      "2              3  0.56  0.40  0.48  0.5  0.49  0.37  0.46\n",
      "3              4  0.59  0.49  0.48  0.5  0.52  0.45  0.36\n",
      "4              5  0.23  0.32  0.48  0.5  0.55  0.25  0.35\n"
     ]
    }
   ],
   "source": [
    "#Reading Data Frame\n",
    "data=pd.read_csv('ecoli.csv')\n",
    "data=data.dropna()\n",
    "Y=data['Class']\n",
    "encoder=LabelEncoder()\n",
    "encoder1=LabelEncoder()\n",
    "Y=encoder.fit_transform(data.iloc[:,-1].astype(str))\n",
    "X=data.drop('Class',axis=1)\n",
    "X[\"Sequence Name\"]=encoder1.fit_transform(data.iloc[:,0].astype(str))\n",
    "print(X.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Learning data with 80% Training and 20% Testing data using Random Forest Method\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,train_size = 0.8,test_size=0.2,random_state=0)\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random forest prediction vs actual tested reading: 0.8970588235294118\n",
      "The confusion Matrix is as Below:\n",
      "\n",
      "[[35  0  0  0  0  0  0  0]\n",
      " [ 1  8  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  5  0  0  0]\n",
      " [ 0  0  0  0  0  4  0  1]\n",
      " [ 0  0  0  0  0  0  1  1]\n",
      " [ 2  0  0  0  0  0  0  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          cp       0.92      1.00      0.96        35\n",
      "          im       0.80      0.89      0.84         9\n",
      "         imL       0.00      0.00      0.00         1\n",
      "         imS       0.00      0.00      0.00         1\n",
      "         imU       1.00      1.00      1.00         5\n",
      "          om       1.00      0.80      0.89         5\n",
      "         omL       1.00      0.50      0.67         2\n",
      "          pp       0.80      0.80      0.80        10\n",
      "\n",
      "   micro avg       0.90      0.90      0.90        68\n",
      "   macro avg       0.69      0.62      0.64        68\n",
      "weighted avg       0.87      0.90      0.88        68\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Evaluating Confusion Matrix and Classification Evaluation Report after Random Forest Learning\n",
    "ypred = clf.predict(x_test)\n",
    "Y1=list(encoder.inverse_transform(y_test))\n",
    "Y2=list(encoder.inverse_transform(ypred))\n",
    "print(\"Accuracy of Random forest prediction vs actual tested reading:\",accuracy_score(y_test, ypred))\n",
    "print('The confusion Matrix is as Below:\\n')\n",
    "\n",
    "print(confusion_matrix(Y1,Y2,labels=list(encoder.classes_)))\n",
    "print(classification_report(Y1,Y2,labels=list(encoder.classes_)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Probability Fields using Binning Techniques\n",
    "yproba=clf.predict_proba(X)\n",
    "\n",
    "binlab=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "\n",
    "bins=[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sequence Name   mcg   gvh   lip  chg   aac  alm1  alm2   p1   p2   p3   p4  \\\n",
      "0              1  0.49  0.29  0.48  0.5  0.56  0.24  0.35  1.0  0.1  0.1  0.1   \n",
      "1              2  0.07  0.40  0.48  0.5  0.54  0.35  0.44  1.0  0.1  0.1  0.1   \n",
      "2              3  0.56  0.40  0.48  0.5  0.49  0.37  0.46  1.0  0.1  0.1  0.1   \n",
      "3              4  0.59  0.49  0.48  0.5  0.52  0.45  0.36  0.9  0.1  0.1  0.1   \n",
      "4              5  0.23  0.32  0.48  0.5  0.55  0.25  0.35  1.0  0.1  0.1  0.1   \n",
      "\n",
      "    p5   p6   p7   p8  \n",
      "0  0.1  0.1  0.1  0.1  \n",
      "1  0.1  0.1  0.1  0.1  \n",
      "2  0.1  0.1  0.1  0.1  \n",
      "3  0.1  0.1  0.1  0.1  \n",
      "4  0.1  0.1  0.1  0.1  \n"
     ]
    }
   ],
   "source": [
    "# Adding Probability fields to the entire feature dataset. \n",
    "X['p1']=pd.cut(yproba[:,0],bins,labels=binlab, include_lowest=True)\n",
    "X['p2']=pd.cut(yproba[:,1],bins,labels=binlab, include_lowest=True)\n",
    "X['p3']=pd.cut(yproba[:,2],bins,labels=binlab, include_lowest=True)\n",
    "X['p4']=pd.cut(yproba[:,3],bins,labels=binlab, include_lowest=True)\n",
    "X['p5']=pd.cut(yproba[:,4],bins,labels=binlab, include_lowest=True)\n",
    "X['p6']=pd.cut(yproba[:,5],bins,labels=binlab, include_lowest=True)\n",
    "X['p7']=pd.cut(yproba[:,6],bins,labels=binlab, include_lowest=True)\n",
    "X['p8']=pd.cut(yproba[:,7],bins,labels=binlab, include_lowest=True)\n",
    "\n",
    "\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=100,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dividing the entire dataset into training and test data and performing Decision Tree classification.\n",
    "xtr1, xte1, ytr1, yte1 = train_test_split(X,Y,train_size = 0.8,test_size=0.2,random_state=0)\n",
    "dt = DecisionTreeClassifier(min_samples_split=100)\n",
    "dt.fit(xtr1,ytr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred1 = dt.predict(xte1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of using decision tree after random forest: 0.75\n",
      "The confusion Matrix is as Below:\n",
      "\n",
      "[[35  0  0  0  0  0  0  0]\n",
      " [ 1  8  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  5]\n",
      " [ 0  0  0  0  0  0  0  5]\n",
      " [ 0  0  0  0  0  0  0  2]\n",
      " [ 2  0  0  0  0  0  0  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          cp       0.92      1.00      0.96        35\n",
      "          im       0.80      0.89      0.84         9\n",
      "         imL       0.00      0.00      0.00         1\n",
      "         imS       0.00      0.00      0.00         1\n",
      "         imU       0.00      0.00      0.00         5\n",
      "          om       0.00      0.00      0.00         5\n",
      "         omL       0.00      0.00      0.00         2\n",
      "          pp       0.40      0.80      0.53        10\n",
      "\n",
      "   micro avg       0.75      0.75      0.75        68\n",
      "   macro avg       0.27      0.34      0.29        68\n",
      "weighted avg       0.64      0.75      0.68        68\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Evaluating Accuracy, Confusion Matrix and Classification Report on Decision Tree After distillation of Random Forest \n",
    "print(\"Accuracy of using decision tree after random forest:\",accuracy_score(yte1, ypred1))\n",
    "Y3=list(encoder.inverse_transform(yte1))\n",
    "Y4=list(encoder.inverse_transform(ypred1))\n",
    "print('The confusion Matrix is as Below:\\n')\n",
    "print(confusion_matrix(Y3,Y4,labels=list(encoder.classes_)))\n",
    "print(classification_report(Y3,Y4,target_names=list(encoder.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trying other Techniques after distillation namely Support Vector Machine\n",
    "xtr1, xte1, ytr1, yte1 = train_test_split(X,Y,train_size = 0.8,test_size=0.2,random_state=0)\n",
    "support = svm.SVC(gamma=0.01, C=100.)\n",
    "support.fit(xtr1,ytr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred1 = support.predict(xte1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of using Support Vector Machine after random forest: 0.6911764705882353\n",
      "The confusion Matrix is as Below:\n",
      "\n",
      "[[30  2  0  0  2  1  0  0]\n",
      " [ 1  7  0  0  1  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0]\n",
      " [ 0  3  0  0  2  0  0  0]\n",
      " [ 2  0  0  0  1  1  0  1]\n",
      " [ 1  1  0  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0  0  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          cp       0.81      0.86      0.83        35\n",
      "          im       0.47      0.78      0.58         9\n",
      "         imL       0.00      0.00      0.00         1\n",
      "         imS       0.00      0.00      0.00         1\n",
      "         imU       0.33      0.40      0.36         5\n",
      "          om       0.50      0.20      0.29         5\n",
      "         omL       0.00      0.00      0.00         2\n",
      "          pp       0.88      0.70      0.78        10\n",
      "\n",
      "   micro avg       0.69      0.69      0.69        68\n",
      "   macro avg       0.37      0.37      0.36        68\n",
      "weighted avg       0.67      0.69      0.67        68\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of using Support Vector Machine after random forest:\",accuracy_score(yte1, ypred1))\n",
    "Y5=list(encoder.inverse_transform(yte1))\n",
    "Y6=list(encoder.inverse_transform(ypred1))\n",
    "print('The confusion Matrix is as Below:\\n')\n",
    "print(confusion_matrix(Y5,Y6,labels=list(encoder.classes_)))\n",
    "print(classification_report(Y5,Y6,target_names=list(encoder.classes_)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=100,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making use of training data without distillation using single not ensemble method like Decision Tree.\n",
    "dt1=DecisionTreeClassifier(min_samples_split=100)\n",
    "dt1.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = dt1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree prediction without distillation: 0.7941176470588235\n",
      "The confusion Matrix is as Below:\n",
      "\n",
      "[[34  0  0  0  0  1  0  0]\n",
      " [ 1  7  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  5  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  4]\n",
      " [ 0  0  0  0  0  2  0  0]\n",
      " [ 1  0  0  0  1  1  0  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          cp       0.94      0.97      0.96        35\n",
      "          im       1.00      0.78      0.88         9\n",
      "         imL       0.00      0.00      0.00         1\n",
      "         imS       0.00      0.00      0.00         1\n",
      "         imU       0.56      1.00      0.71         5\n",
      "          om       0.20      0.20      0.20         5\n",
      "         omL       0.00      0.00      0.00         2\n",
      "          pp       0.64      0.70      0.67        10\n",
      "\n",
      "   micro avg       0.79      0.79      0.79        68\n",
      "   macro avg       0.42      0.46      0.43        68\n",
      "weighted avg       0.77      0.79      0.77        68\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "Y7=list(encoder.inverse_transform(y_test))\n",
    "Y8=list(encoder.inverse_transform(ypred))\n",
    "print(\"Accuracy of Decision Tree prediction without distillation:\",accuracy_score(y_test, ypred))\n",
    "print('The confusion Matrix is as Below:\\n')\n",
    "print(confusion_matrix(Y7,Y8,labels=list(encoder.classes_)))\n",
    "print(classification_report(Y7,Y8,target_names=list(encoder.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sequence Name   mcg   gvh   lip  chg   aac  alm1  alm2\n",
      "0              1  0.49  0.29  0.48  0.5  0.56  0.24  0.35\n",
      "1              2  0.07  0.40  0.48  0.5  0.54  0.35  0.44\n",
      "2              3  0.56  0.40  0.48  0.5  0.49  0.37  0.46\n",
      "3              4  0.59  0.49  0.48  0.5  0.52  0.45  0.36\n",
      "4              5  0.23  0.32  0.48  0.5  0.55  0.25  0.35\n",
      "   Sequence Name   mcg   gvh   lip  chg   aac  alm1  alm2   p1   p2   p3   p4  \\\n",
      "0              1  0.49  0.29  0.48  0.5  0.56  0.24  0.35  1.0  0.1  0.1  0.1   \n",
      "1              2  0.07  0.40  0.48  0.5  0.54  0.35  0.44  0.8  0.2  0.1  0.1   \n",
      "2              3  0.56  0.40  0.48  0.5  0.49  0.37  0.46  1.0  0.1  0.1  0.1   \n",
      "3              4  0.59  0.49  0.48  0.5  0.52  0.45  0.36  1.0  0.1  0.1  0.1   \n",
      "4              5  0.23  0.32  0.48  0.5  0.55  0.25  0.35  1.0  0.1  0.1  0.1   \n",
      "\n",
      "    p5   p6   p7  \n",
      "0  0.1  0.1  0.1  \n",
      "1  0.1  0.1  0.1  \n",
      "2  0.1  0.1  0.1  \n",
      "3  0.1  0.1  0.1  \n",
      "4  0.1  0.1  0.1  \n"
     ]
    }
   ],
   "source": [
    "# Adding Probability fields to the entire feature dataset and binning. \n",
    "X1=data.drop('Class',axis=1)\n",
    "X1[\"Sequence Name\"]=encoder1.fit_transform(data.iloc[:,0].astype(str))\n",
    "print(X1.head())\n",
    "\n",
    "yproba1=dt1.predict_proba(X1)\n",
    "\n",
    "binlab=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "\n",
    "bins=[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "\n",
    "X1['p1']=pd.cut(yproba1[:,0],bins,labels=binlab, include_lowest=True)\n",
    "X1['p2']=pd.cut(yproba1[:,1],bins,labels=binlab, include_lowest=True)\n",
    "X1['p3']=pd.cut(yproba1[:,2],bins,labels=binlab, include_lowest=True)\n",
    "X1['p4']=pd.cut(yproba1[:,3],bins,labels=binlab, include_lowest=True)\n",
    "X1['p5']=pd.cut(yproba1[:,4],bins,labels=binlab, include_lowest=True)\n",
    "X1['p6']=pd.cut(yproba1[:,5],bins,labels=binlab, include_lowest=True)\n",
    "X1['p7']=pd.cut(yproba1[:,6],bins,labels=binlab, include_lowest=True)\n",
    "\n",
    "print(X1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=100,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying Decision Tree after Distillation using individual Learning like Decision Tree\n",
    "xtr1, xte1, ytr1, yte1 = train_test_split(X1,Y,train_size = 0.8,test_size=0.2,random_state=0)\n",
    "dt2 = DecisionTreeClassifier(min_samples_split=100)\n",
    "dt2.fit(xtr1,ytr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred2 = dt2.predict(xte1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of using decision tree after distillation using decision tree: 0.7941176470588235\n",
      "The confusion Matrix is as Below:\n",
      "\n",
      "[[34  0  0  0  0  0  0  1]\n",
      " [ 1  7  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  5  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  5]\n",
      " [ 0  0  0  0  0  0  0  2]\n",
      " [ 1  0  0  0  1  0  0  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          cp       0.94      0.97      0.96        35\n",
      "          im       1.00      0.78      0.88         9\n",
      "         imL       0.00      0.00      0.00         1\n",
      "         imS       0.00      0.00      0.00         1\n",
      "         imU       0.56      1.00      0.71         5\n",
      "          om       0.00      0.00      0.00         5\n",
      "         omL       0.00      0.00      0.00         2\n",
      "          pp       0.50      0.80      0.62        10\n",
      "\n",
      "   micro avg       0.79      0.79      0.79        68\n",
      "   macro avg       0.38      0.44      0.40        68\n",
      "weighted avg       0.73      0.79      0.75        68\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of using decision tree after distillation using decision tree:\",accuracy_score(yte1, ypred2))\n",
    "Y9=list(encoder.inverse_transform(yte1))\n",
    "Y10=list(encoder.inverse_transform(ypred2))\n",
    "print('The confusion Matrix is as Below:\\n')\n",
    "print(confusion_matrix(Y9,Y10,labels=list(encoder.classes_)))\n",
    "print(classification_report(Y9,Y10,target_names=list(encoder.classes_)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
